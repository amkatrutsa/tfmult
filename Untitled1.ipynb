{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jacobi_2d(b, init_U=None, max_iter=10):\n",
    "    '''\n",
    "    Computes Jacobi solution for 2d Poisson equations\n",
    "    Args:\n",
    "        b: A `Tensor` of (batch, m, n, 1) shape, \n",
    "            right-hand sides of equations\n",
    "        init_U: A `Tensor` of (batch, m, n, 1) shape,\n",
    "            initial guess for solution\n",
    "        max_iter: An `int`, \n",
    "            number of iterations\n",
    "    Returns:\n",
    "        A `tensor` of (batch, m, n, 1) shape,\n",
    "            solution of 2d Poisson equation\n",
    "    '''\n",
    "    inv_d = 1.0 / 4  # inverted A's diagonal element\n",
    "    if init_U is None:\n",
    "        cur_U = tf.random_normal(tf.shape(b), mean=0, stddev=0.01)\n",
    "    else:\n",
    "        cur_U = tf.identity(init_U)\n",
    "    kernel = tf.reshape(tf.constant([-1, 0, -1], 'float'), [3, 1, 1, 1])\n",
    "    for n_iter in range(max_iter):\n",
    "        prev_U = tf.identity(cur_U)\n",
    "        diag_block = tf.nn.conv2d(cur_U, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        nondiag_block = tf.concat(2, [cur_U[:, :, 1:2, :], \n",
    "                                      (cur_U[:, :, 0:-2, :] + cur_U[:, :, 2:, :]), \n",
    "                                      cur_U[:, :, -2:-1, :]])\n",
    "        cur_U = (b - diag_block + nondiag_block) * inv_d\n",
    "    return cur_U\n",
    "\n",
    "def compute_2d_laplacian_convolution(U):\n",
    "    '''\n",
    "    Computes \"matvec\" for 2d laplacian\n",
    "    Args:\n",
    "        U: A `Tensor` of (batch, m, n, 1) or (batch, m, n) shape\n",
    "    Returns:\n",
    "        A `Tensor` of (batch, m, n, 1) shape\n",
    "    '''\n",
    "    batch = tf.shape(U)[0]\n",
    "    m = tf.shape(U)[1]\n",
    "    n = tf.shape(U)[2]\n",
    "    U = tf.reshape(U, (batch, m, n, 1))\n",
    "    kernel = tf.reshape(tf.constant([-1, 4, -1], 'float'), [3, 1, 1, 1])\n",
    "    diag_block = tf.nn.conv2d(U, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    nondiag_block = tf.concat(2, [U[:, :, 1:2, :], \n",
    "                                      (U[:, :, 0:-2, :] + U[:, :, 2:, :]), \n",
    "                                      U[:, :, -2:-1, :]])\n",
    "    return diag_block - nondiag_block\n",
    "\n",
    "def compute_R(U, R):\n",
    "    '''\n",
    "    Computes restriction of U\n",
    "    Args:\n",
    "        U: A `Tensor` of (batch, 2 ** m - 1, 2 ** n - 1, 1) shape,\n",
    "            data to convolve\n",
    "        R: A `Tensor` of (1, 3, 3, 1) shape,\n",
    "            restriction operator stencil\n",
    "    Returns:\n",
    "        A `Tensor` of (batch, 2 ** (m - 1) - 1, 2 ** (n - 1) - 1, 1) shape\n",
    "    '''\n",
    "    return tf.nn.conv2d(U, R, strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "def compute_P(U, P):\n",
    "    '''\n",
    "    Computes prolongation of U\n",
    "    Args:\n",
    "        U: A `Tensor` of (batch, 2 ** m - 1, 2 ** n - 1, 1) shape,\n",
    "            data to convolve\n",
    "        P: A `Tensor` of (1, 3, 3, 1) shape,\n",
    "            projection operator stencil\n",
    "    Returns:\n",
    "        A `Tensor` of (batch, 2 ** (m + 1) - 1, 2 ** (n + 1) - 1, 1) shape\n",
    "    '''\n",
    "    a_shape = tf.to_int32(tf.shape(U)[0:1])\n",
    "    b_shape = tf.to_int32((tf.shape(U)[1:3] + 1) * 2 - 1)\n",
    "    c_shape = tf.constant([1], dtype=tf.int32)\n",
    "    output_shape = tf.concat(0, [a_shape, b_shape, c_shape])\n",
    "    return tf.nn.conv2d_transpose(U, P, output_shape=output_shape, \n",
    "                                  strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "def V_cycle(level, b, init_U=None, P=None, R=None, smoother_iter=3, \n",
    "            solution_iter=20):\n",
    "    '''\n",
    "    Applies one multigrid V-cycle to Poisson 2d equation\n",
    "    Args:\n",
    "        level: An `int`, \n",
    "            number of multigrid levels\n",
    "        b: A `Tensor` of (batch, m, n) shape, \n",
    "            right-hand sides of equations\n",
    "        init_U: A `Tensor` of (batch, m, n) shape or None,\n",
    "            initial guess for solution, \n",
    "            if init_U is None, it will be random\n",
    "        P: A `Tensor` variable of (3, 3, 1, 1) shape,\n",
    "            prolongation operator stencil\n",
    "        R: A `Tensor` variable of (3, 3, 1, 1) shape,\n",
    "            restriction operator stencil\n",
    "        smoother_iter: An `int`,\n",
    "            number of smoother iterations\n",
    "        solution_iter: An `int`, \n",
    "            number of solution iterations\n",
    "    Returns:\n",
    "        A `Tensor` of (batch, m, n) shape,\n",
    "        multigrid solution\n",
    "    '''\n",
    "    if init_U is None:\n",
    "        init_U = tf.random_normal((tf.shape(b)), stddev=0.01)\n",
    "    if level == 0:\n",
    "        new_U = jacobi_2d(b, init_U, max_iter=solution_iter)\n",
    "    else:\n",
    "        U = jacobi_2d(b, init_U, max_iter=smoother_iter)\n",
    "        Au = compute_2d_laplacian_convolution(U)\n",
    "        res = compute_R(Au - b, R)\n",
    "        e = tf.zeros_like(res)\n",
    "        e = V_cycle(level - 1, b=res, init_U=e, P=P, R=R, \n",
    "                    smoother_iter=smoother_iter, solution_iter=solution_iter)\n",
    "        new_U = U + compute_P(e, P)\n",
    "    return new_U\n",
    "    \n",
    "def multigrid(n_cycles, level, b, init_U=None, P=None, R=None, smoother_iter=3, \n",
    "            solution_iter=20):\n",
    "    '''\n",
    "    Computes multigrid solution of 2d Poisson equation\n",
    "    Args:\n",
    "        n_cycles: An `int`, \n",
    "            number of V-cycles\n",
    "        b and init_U have shape (batch, m, n)\n",
    "        other args are the same as in V_cycle function\n",
    "    Returns:\n",
    "        A `Tensor` of (batch, m, n) shape,\n",
    "        multigrid solution\n",
    "    '''\n",
    "    batch = tf.shape(b)[0]\n",
    "    m = tf.shape(b)[1]\n",
    "    n = tf.shape(b)[2]\n",
    "    b = tf.reshape(b, (batch, m, n, 1))\n",
    "    if init_U is None:\n",
    "        init_U = tf.random_normal((tf.shape(b)), stddev=0.01)\n",
    "    else:\n",
    "        init_U = init_U.reshape(init_U, (batch, m, n, 1))\n",
    "    if P is None:\n",
    "        P = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) /  4., [3, 3, 1, 1])\n",
    "    if R is None:\n",
    "        R = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) / 16., [3, 3, 1, 1])\n",
    "    for cycle_idx in range(n_cycles):\n",
    "        init_U = V_cycle(level, b, init_U, P, R, smoother_iter, solution_iter)\n",
    "    return init_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dim check for multigrid:\n",
    "P = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) /  4., [3, 3, 1, 1])\n",
    "R = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) / 16., [3, 3, 1, 1])\n",
    "batch = 20\n",
    "m = 31\n",
    "n = 63\n",
    "np_b = np.random.random((batch, m, n, 1))\n",
    "b = tf.placeholder('float', name='b')\n",
    "res = multigrid(n_cycles=3, level=5, b=b, solution_iter=20, smoother_iter=5, P=P, R=R)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4)) as sess:\n",
    "    sess.run(init_op)\n",
    "    solution = sess.run(res, feed_dict={b: np_b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check numerical multigrid results:\n",
    "batch = 1\n",
    "m = 63\n",
    "n = 63\n",
    "P = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) /  4., [3, 3, 1, 1])\n",
    "R = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) / 16., [3, 3, 1, 1])\n",
    "U = tf.constant(np.random.uniform(-100, 100, (m * n)).reshape(batch, m, n, 1), dtype=tf.float32)\n",
    "b = compute_2d_laplacian_convolution(U)\n",
    "multigrid_U = multigrid(n_cycles=10, level=5, b=b, solution_iter=100, smoother_iter=10, P=P, R=R)\n",
    "max_diff = tf.reduce_max(tf.abs(U - multigrid_U))\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4)) as sess:\n",
    "    sess.run(init_op)\n",
    "    np_max_diff = sess.run(max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(m * n).reshape(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.arange(m * n).reshape(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   4.,   2.],\n",
       "       [  5.,  10.,  12.,   6.],\n",
       "       [  9.,  18.,  20.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_b[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7, 7, 1)\n",
      "(50, 15, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check compute_P:\n",
    "P = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) / 16., [3, 3, 1, 1])\n",
    "U = tf.placeholder('float')\n",
    "np_data = np.random.random((50, 7, 7, 1))\n",
    "print(np_data.shape)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    projection = sess.run(compute_P(U, P), feed_dict={U: np_data})\n",
    "    print(projection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7, 7, 1)\n",
      "(50, 3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check compute_R:\n",
    "P = tf.reshape(tf.Variable(tf.constant(np.array([\n",
    "                        [1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]\n",
    "                    ]), dtype='float')) / 16., [3, 3, 1, 1])\n",
    "U = tf.placeholder('float')\n",
    "np_data = np.random.random((50, 7, 7, 1))\n",
    "print(np_data.shape)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    restriction = sess.run(compute_R(U, R), feed_dict={U: np_data})\n",
    "    print(restriction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check compute_2d_laplacian_convolution:\n",
    "batch = 1\n",
    "m = 3\n",
    "n = 4\n",
    "data = tf.ones((batch, m, n, 1))\n",
    "b = compute_2d_laplacian_convolution(data)\n",
    "with tf.Session() as sess:\n",
    "    tmp = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  1.  1.  2.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 2.  1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(tmp[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
